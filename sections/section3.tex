
\section{Definitions}

\subsection*{Preliminaries}

\begin{frame}{Context-Free Grammar (CFG)}{Foundation that attribute grammars built upon}

Context-free grammar consists of:
\begin{itemize}
    \item a set of non-terminals, one of which is designated as the start variable
    \item a set of terminals
    \item a set of productions
\end{itemize}
\end{frame}

\note[itemize]{
\item What is grammar or more specifically context-free grammar?
\item Grammar is a tuple of a set of non-terminals, a set of terminals, and a set of productions.
}

\begin{frame}[fragile=singleslide]{Example}{Grammar for a simple language}

\begin{multicols}{2}
\begin{Verbatim}[fontsize=\scriptsize]
program -> block

block -> "begin" decls stmts "end"

decls -> decls decl
    |   /* empty */

decl -> ID ":" type ";"

type -> "Integer"
    |   "String"

stmts -> stmts stmt
    |   /* empty */

stmt -> expr ":=" expr
    |   block ";"

expr -> INT_CONSTANT
    |   STRING_CONSTANT
    |   ID
\end{Verbatim}
\end{multicols}


Source: \cite{Boyland1998AnalyzingDN}

\end{frame}

\note[itemize]{
\item This is an example of grammar that defines a simple program that declares some variables and assigns them to an expression
\item Notice that it starts from a program and goes to a block
\item Block consists of declarations and assignments
}


\begin{frame}[fragile=singleslide]{CFG Example}{A derivation of this simple language}

    \begin{columns}
    \column{0.5\textwidth}
\begin{Verbatim}[fontsize=\scriptsize,numbers=left,xleftmargin=5mm]
begin
   x : String;
   y : Integer;
	
   x := z;
   y := "hello world!";
end
\end{Verbatim}

    \column{0.5\textwidth}
\alert{Semantic Errors}
\begin{itemize}
    \item Use of undeclared variable?
    \item Type mismatch?
    \item Unused variable?
\end{itemize}
    \end{columns}

\newlinevspace

$\Rightarrow$ How to \alert{identity} these issues \alert{using} \emph{attribute grammars} ...?
\end{frame}

\note[itemize]{
\item This is a program or a derivation of the context-free grammar that we saw in the previous slide
\item Notice there are multiple semantic errors in this program, can you identify them?
}



\begin{frame}{Classical Attribute Grammar}{CFG + Rules}


A classical attribute grammar is a \alert{CFG grammar} with the following added features:

\begin{itemize}
    \item Each non-terminal $X$ has a set of attributes $A(X)$
    \item $A(X)$ has two disjoint subsets
    \begin{itemize}
        \item $S(X)$, synthesized attributes, which are passed up the tree
        \item $I(X)$, inherited attributes which are passed down the tree
    \end{itemize}
    \item Set of local attributes associated with each production
    \item Each production of the grammar has a set of semantic rules
\end{itemize}

\end{frame}

\note[itemize]{
\item What is a classical attribute grammar?
\item It is a tuple of context-free grammar, a set of attributes for each non-terminal, set of local attributes and each production has a set of semantic rules that defines some attributes for the LHS of the production
}





\begin{frame}[fragile=singleslide]{Semantic Function}{Identity function syntactic sugar}

\begin{verbatim}
A -> B c       // CFG production
    A.s = B.s  // <-- semantic function: A.s = id(B.s)
               // with one argument
               // returns the argument
\end{verbatim}

This particular semantic function is called an \alert{identity function}

\end{frame}

\note[itemize]{
\item This is just a syntax sugar we will be using throughout this presentation
}









\begin{frame}[fragile=singleslide]{Example}{Classical attribute grammar to find semantic errors in a program}


\begin{multicols}{2}
\begin{Verbatim}[fontsize=\fontsize{1}{1}\selectfont]
program -> block
	block.env = empty_env()
	program.msgs = block.msgs
	
block -> "begin" decls stmts "end"
	decls.envin = block.env
	stmts.env = decls.envout
	decls.uin = stmts.used
	block.used = decls.uout
	block.msgs = decls.msgs ++ stmts.msgs
	
decls ->
	decls.envout = decls.envin
	decls.uout = decls.uin
	decls.msgs = { }

decls -> decls decl
  decls1.envin = decls0.envin
  decl.envin = decls1.envout
  decls0.envout = decl.envout
  decl.uin = decls0.uin
  decls1.uin = decl.uout
  decls0.uout = decls1.uout
  decls0.msgs = decls1.msgs ++ decl.msgs

decl -> id ":" type ";"
  decl.envout = add_env(<id, type.shape>, decl.envin)
  decl.uout = decl.uin - id
  decl.msgs = if id in decl.uin then
                { }
              else
                { "unused: " + id }

type -> "Integer"
  type.shape = INT_SHAPE

type -> "String"
  type.shape = STR_SHAPE

stmt ->
  stmts.used = { }
  stmts.msgs = { }

stmts -> stmts stmt
  stmts1.env = stmts0.env
  stmt.env = stmts0.env
  stmts0.used = stmts1.used ++ stmt.used
  stmts0.msgs = stmts1.msgs ++ stmt.msgs

stmt -> block ";"
  block.env = stmt.env
  stmt.used = block.used
  stmt.msgs = block.msgs

stmts -> expr ":=" expr ";"
  expr1.env = stmt.env
  expr2.env = stmt.env
  stmt.used = expr1.used ++ expr2.used
  stmt.msgs = (if expr1.shape != expr2.shape then
                { "type mismatch" }
              else
                { }) ++ expr.msgs

expr -> INT_CONSTANT
  expr.shape = INT_SHAPE
  expr.used = { }
  expr.msgs = { }

expr -> STR_CONSTANT
  expr.shape = STR_SHAPE
  expr.used = { }
  expr.msgs = { }

expr -> id
  local shape = lookup(id, expr.env)
  expr.shape = shape
  expr.used = { id }
  expr.msgs = if shape == NOT_FOUND then
                { id + " not declared" }
              else
                { }
\end{Verbatim}
\end{multicols}

\end{frame}

\note[itemize]{
\item This is a classical attribute grammar that detects: type mismatch, unused variables, and use of undeclared variable that we identified in the previous slide
\item $\mathit{msgs}$ is a synthesized collection attribute of error messages
\item $\mathit{env}$ is an inherited attribute that denotes the set of variables declared and available to us
\item $\mathit{used}$ is a set of all variables used as an expression
}


\begin{frame}{Instantiated Attribute Grammar}{Attribute Grammar + Derivation = Instantiated AG}
Given a \alert{derivation} of CFG grammar, an attribute grammar becomes \alert{instantiated}:
\begin{itemize}
    \item Set of instantiated semantic rules where each attribute \alert{occurrence} is replaced with an \alert{attribute instance}
\end{itemize}

\end{frame}

\note[itemize]{
\item Combining an attribute grammar and a derivation results in an instantiated attribute grammar where instead of attribute occurrences we have attribute instances.
}

\subsection*{Evaluations}

\begin{frame}{Evaluation}{Core concept}

\begin{itemize}
    \item Evaluation is a process of finding the \alert{values} of \alert{attribute instances}.

    \item Two types of evaluation:
\begin{itemize}
    \item Demand evaluation
    \item Static evaluation
\end{itemize}
\end{itemize}

\end{frame}

\note[itemize]{
\item We observed that semantic information is stored in attributes
\item The \enquote{values} of attributes are the result of evaluation rules associated with productions of the grammar
\item and the evaluation is a process of finding the values of attribute instances
\item There are two types of evaluations: static and demand
\item Demand is a kind of evaluation where the evaluator demands each attribute value (usually root node's synthesized attributes), we don't know if the evaluation will succeed or not until the evaluation finishes and it requires runtime dependency graph
\item Static evaluation is the opposite.
}


\begin{frame}{Demand Evaluation}{Straightforward evaluation method}
\begin{definition}
Demand evaluation is a kind of evaluation where each attribute instance access requires a call to evaluate the corresponding instantiated semantic rule that defines it.
\end{definition}

\begin{alertblock}{Observation}
In demand evaluation, we do not know whether the evaluation will succeed or not until the evaluation finishes
\end{alertblock}

\begin{alertblock}{Observation}
Demand evaluation requires a runtime dependency graph
\end{alertblock}

\end{frame}

\note[itemize]{
\item Demand evaluation replaces access to the value of an attribute instance with a function call that defines the attribute in the first place
\item Basically, during the evaluation runtime, the evaluator tries to figure out which rule it should evaluate next
\item This form of evaluation is simple but it has some downsides
}

\begin{frame}[fragile=singleslide]{Example}{Example of classical attribute grammar}
    
\begin{multicols}{3}
\begin{verbatim}
S -> A
  A.i1  = S.in
  A.i2  = A.s1
  S.out = A.s2




A -> A A
  A1.i1 = A0.i1
  A1.i2 = A1.s1
  A0.s1 = A1.s2
  A2.i1 = A0.i2
  A2.i2 = A2.s1
  A0.s2 = A2.s2

A -> 'a'
  A.s1 = A.i1 + 1
  A.s2 = A.i2 + 2
    
    
    
    
\end{verbatim}
\end{multicols}

Source: \cite{10.1145/225540.225544}
    
\end{frame}

\note[itemize]{
\item This is an example of classical attribute grammar
\item Notice root non-terminal $S$ has two attributes, one inherited and one synthesized
\item Similarly, non-terminal $A$ has two inherited and two synthesized attributes
}


\begin{frame}[fragile=singleslide]{Derivation}{4 nodes in the tree}

\[
\lefteqn{\underbrace{\phantom{S \rightarrow A}}_{n_0}} S \rightarrow
\lefteqn{\overbrace{\phantom{A \rightarrow A A}}^{n_1}} A \rightarrow 
\lefteqn{\underbrace{\phantom{A A \rightarrow \texttt{a}}}_{n_2}} A A \rightarrow \texttt{a}
\lefteqn{\overbrace{A \rightarrow \texttt{aa}}^{n_3}}
\]

\begin{center}
\scalebox{0.75}{\begin{forest}
  [
    $n_0$, name=n0
    [ $n_1$
        [$n_2$ [$\texttt{a}$]]
        [$n_3$ [$\texttt{a}$]]
    ]
  ]
\end{forest}}
\end{center}

\end{frame}

\note[itemize]{
\item This derivation results in 4 nodes in the syntax tree
}

\begin{frame}[fragile=singleslide]{Example}{Instantiated attribute grammar}


\begin{multicols}{3}
\begin{Verbatim}[fontsize=\scriptsize]
n0: S -> A
  r0 : n1.i1  = n0.in
  r1 : n1.i2  = n1.s1
  r2 : n0.out = n1.s2




n1: A -> A A
  r3 : n2.i1 = n1.i1
  r4 : n2.i2 = n2.s1
  r5 : n1.s1 = n2.s2
  r6 : n3.i1 = n1.i2
  r7 : n3.i2 = n3.s1
  r8 : n1.s2 = n3.s2

n2: A -> 'a'
  r9 : n2.s1 = n2.i1 + 1
  r10: n2.s2 = n2.i2 + 2
    
n3: A -> 'a'
  r11: n3.s1 = n3.i1 + 1
  r12: n3.s2 = n3.i2 + 2
\end{Verbatim}
\end{multicols}

The sequence of steps needed to evaluate $\alert{n_0.\mathit{out}}$:
$\alert{n_0.\mathit{out}} \to \alert{r_2}{:} n_o.\mathit{out} = n_1.s_2 \to \alert{r_8}{:} n_1.s_2 = n_3.s_2 \to \alert{r_{12}}{:}n_3.s_2 = \dots$

\end{frame}

\note[itemize]{
\item This is the instantiated form of an attribute grammar we saw in the previous slide
\item $n_0$, $n_1$, $n_2$ and $n_3$ are tree nodes
\item $n_i$ followed by a dot followed by attribute name is called an attribute instance
\item Also, notice the sequence of steps a demand evaluator needs to take during the evaluation runtime to evaluate the root node's synthesized attribute $n_0.\mathit{out}$
\item This sequence of instantiated rules used to evaluate all attribute instances is called a schedule
\item We have to run a topological sort on an instantiated attribute grammar to find the schedule
}

\begin{frame}{Schedule}{Total order of instantiated rules}
What makes a schedule (total order on instantiated rules) valid?

\newlinevspace

$\Rightarrow$ \alert{No use of attribute instance before it is defined first}

\end{frame}

\note[itemize]{
\item In a valid schedule, we have to arrange the instantiated rules such that no attribute instance is used before it is defined first.
\item So definition of an attribute instance has to precede the use.
}

\begin{frame}{Demand Evaluation}{Pros and cons}
Pros:
\begin{itemize}
    \item Can benefit form \alert{caching to prevent re-evaluation}
    \item Easy to implement
\end{itemize}

Cons:
\begin{itemize}
    \item Does not detect cycles before the evaluation begins and \alert{may not terminate}
    \item Space complexity if \alert{caching} is used: $\mathcal{O}(|\hat{V}|)$
    \item Time complexity of: $\mathcal{O}(| \hat{V} | \times | \hat{R} |)$ (for classical AG)
\end{itemize}
\end{frame}

\note[itemize]{
\item Demand evaluation has some downsides
\item We have to use a cache to avoid exponential time complexity because everything will get evaluated over and over again and caching will impact the space complexity
\item Also, it does not detect cycles in the dependency graph before the evaluation begins and we do not know if evaluation is going to terminate or not. So this is not ideal.
}


\begin{frame}{Schedule Evaluation}{Finding the order of evaluation of instantiated rules before evaluation runtime}

Given this \emph{schedule}, evaluate the AG:

\begin{equation}
\begin{split}
\mathit{schedule} = \Big \{\hat{r}_0 < \hat{r}_3 < \hat{r}_9 < \hat{r}_4 < \hat{r}_{10} < \hat{r}_5 < \hat{r}_1 < \hat{r}_6 \\
< \hat{r}_{11} < \hat{r}_7 < \hat{r}_{12} < \hat{r}_8 < \hat{r}_2 \Big \}    
\end{split}
\end{equation}

\begin{alertblock}{Observation}
Finding the schedule requires topological sort of attribute instances: $\mathcal{O}(| V +  E|)$ where $V = \hat{V}$ and $E = |\hat{V}  \times  \hat{R}|$
\end{alertblock}
\end{frame}

\note[itemize]{
\item Schedule evaluation is a type of dynamic evaluation where we find the schedule beforehand and then during the evaluation runtime, we evaluate the instantiated rules according to the schedule.
\item This is the schedule for the instantiated attribute grammar we saw in the previous slide
\item We use $r$ hat to represent instantiated rules
}




\begin{frame}{Schedule Evaluation}{Pros and cons}
Pros:
\begin{itemize}
    \item If scheduler finds a schedule, then evaluation \alert{will terminate}
    \item Easy to implement
    \item \alert{No possibility of re-evaluation}
    \item Better space complexity as caching is not used
    \item Time complexity of: $\mathcal{O}(| \hat{R} |)$ (for classical AG)
\end{itemize}

Cons:
\begin{itemize}
    \item Schedule \alert{works only for one derivation} of attribute grammar
\end{itemize}
\end{frame}

\note[itemize]{
\item Schedule evaluator runs in a linear time for classical attribute grammar
\item Doesn't require a cache
\item But it only works for one derivation, and if we are given a different derivation then we need to find a different schedule. So this is not ideal.
}






\begin{frame}{Static Evaluation}{Alternative evaluation method: Constructed independent of a particular derivation}

\begin{itemize}
    \item You may be wondering, what if there was a way to \alert{statically} evaluate attribute grammars?
    \begin{itemize}
        \item Generate evaluator \alert{once} and would \alert{work for all possible derivations} of an attribute grammar.
    \end{itemize}
    \item What \alert{constraints} need to be true for such an attribute grammar to have a static evaluator?
    \item Can we guarantee the evaluation always \alert{terminate}?
    \item How to verify if static evaluation is \alert{valid}?
\end{itemize}
\end{frame}

\note[itemize]{
\item What if there was a better way to evaluate attributes? some kind of static evaluator that would create the schedule in the runtime and evaluate a classical attribute grammar in a linear time? this would be ideal.
}


\begin{frame}{Visit Sequence Evaluation}{Static evaluator}

$\Rightarrow$ \alert{Visit sequence evaluation} is a type of \alert{static evaluation}.

\newlinevspace

Pros:
\begin{itemize}
    \item Evaluation \alert{will terminate}
    \item Easy to implement
    \item \alert{No re-evaluation}
    \item Better space complexity as caching is not used
    \item Time complexity of: $\mathcal{O}(| \hat{R} |)$ (for classical AG)
    \item \alert{Practical}: can be generated independent of derivation
\end{itemize}

Cons:
\begin{itemize}
    \item Only works on \alert{$l$-ordered} class of attribute grammars
\end{itemize}
\end{frame}

\note[itemize]{
\item Kastens introduced $l$-ordered class of attribute grammars and introduced a type of static evaluator called a visit sequence evaluator. 
\item Visit sequence evaluator does not require caching
\item and runs in linear time for a classical attribute grammar
\item and can be generated once and works for all derivations of a grammar
\item but only works for $l$-ordered class of attribute grammars
}



\begin{frame}[fragile=singleslide]{Example}{Visit sequence evaluator}

$\Rightarrow$ Set of \alert{recursive functions} where each function takes an \alert{instance of non-terminal} (derivation tree node)

\begin{multicols}{2}
\begin{Verbatim}[fontsize=\scriptsize]
visit_S(n: S -> A)
    A.i1 = S.in
    - visit_A_part1(A)
    A.i2 = A.s1
    - visit_A_part2(A)
    S.out = A.s2

visit_A_part1(n: A -> A A)
    A1.i1 = A0.i1
    - visit_A_part1(A1)
    A1.i2 = A1.s1
    - visit_A_part2(A1)
    A0.s1 = A1.s2
visit_A_part2(n: A -> A A)
    A2.i1 = A0.i2
    - visit_A_part1(A2)
    A2.i2 = A2.s1
    - visit_A_part2(A2)
    A0.s2 = A2.s2

visit_A_part1(n: A -> 'a')
    A.s1 = A.i1 + 1

visit_A_part2(n: A -> 'a')
    A.s2 = A.i2 + 1
    
\end{Verbatim}
\end{multicols}
\end{frame}

\note[itemize]{
\item This is a visit sequence evaluator for the classical attribute grammar we described previously
}


\begin{frame}{$l$-ORD}{$T(X)$: Total order of attributes for non-terminal $X$ }

\[  T(S) = \{ S.\mathit{in} < S.\mathit{out}  \}  \]

\[  T(A) = \{ A.i_1 < A.i_2 < A.s_1 < A.s_2 \}  \]

\newlinevspace

$\Rightarrow$ AG is $l$-ordered if exists a $T(X)$  for all non-terminal $X \in N$ such that its \alert{compatible} with $\mathit{Ord}(\mathit{AO}(p))$ and $\mathit{Ord}(R(p))$ where $p: X \rightarrow \alpha$. 

\end{frame}

\note[itemize]{
\item What is an $l$-ordered class of attribute grammars?
\item We say that AG is $l$-ordered if there is a total order of attributes for a non-terminal such that its compatible with the ordered set of all attribute occurrences for a production $\mathit{AO}(p)$ and ordered set of all rules associated with a production $R(p)$. 
}



\begin{frame}{Visit Sequence}{Protocol}

\begin{definition}
A \emph{Protocol} $\Pi(X)$ is an \alert{ordered partition of attributes} for each non-terminal $X \in N$, where it can include an empty set or multiple synthesized or inherited attributes.
\end{definition}

\newlinevspace

\begin{examples}
For example, $\Pi(A)$ is the following:
\[ \Pi(A) = \Big\{ \{ A.i_1, A.s_1 \} < \{ A.i_2, A.s_2 \} \Big\} \]
\end{examples}

Visit Sequence has to be compatible with $\mathit{Ord}(R(p))$ and $\Pi(X_i)$

\end{frame}

\note[itemize]{
\item To understand a visit sequence we first need to understand a protocol which is like an interface in a programming language
\item A protocol for a non-terminal is an ordered partition of attributes. This may include an empty set or multiple synthesized or inherited attributes.
\item A visit sequence for a production has to be compatible with an ordered set of all rules associated with a production $R(p)$ and protocol for all non-terminals involving in a production.
}



\begin{frame}{Visualization Tools}{Dependency graph}

\begin{figure}[htbp]
    \centering
    \resizebox{.8\textwidth}{!}{
    \begin{tikzpicture}[->,>=Stealth,auto,
        thick,main node/.style={draw, rectangle, align=center, text width=1cm}]

\node[main node, ] (1) at (-2,4)   {$A_0.i_1$};
\node[main node, anchor=north west] (2) at(1.north east) {$A_0.i_2$};
\node[main node, anchor=south west] (3) at(2.north east) {$A_0.s_1$};
\node[main node, anchor=north west] (4) at(3.north east) {$A_0.s_2$};


\node[main node, ] (5) at (-6,0)   {$A_1.i_1$};
\node[main node, anchor=north west] (6) at(5.north east) {$A_1.i_2$};
\node[main node, anchor=south west] (7) at(6.north east) {$A_1.s_1$};
\node[main node, anchor=north west] (8) at(7.north east) {$A_1.s_2$};

\node[main node, ] (9) at (2,0)   {$A_2.i_1$};
\node[main node, anchor=north west] (10) at(9.north east) {$A_2.i_2$};
\node[main node, anchor=south west] (11) at(10.north east) {$A_2.s_1$};
\node[main node, anchor=north west] (12) at(11.north east) {$A_2.s_2$};

\draw (12.north) to[out=90, in=-90, looseness=1] (4.south);
\draw (2.south) to[out=-90, in=90, looseness=1] (9.north);
\draw (8.north) to[out=90, in=-90, looseness=1] (3.south);
\draw (1.south) to[out=-90, in=90, looseness=1] (5.north);

\draw (11.north) to[out=90, in=90, looseness=1.5] (10.north);
\draw (7.north) to[out=90, in=90, looseness=1.5] (6.north);


\end{tikzpicture}}

    \caption{Dependency graph $\mathit{DG}_{p: A \rightarrow A A}$}
\end{figure}

\end{frame}

\note[itemize]{
\item We can draw a dependency graph to visualize dependencies between attribute occurrences in a production
\item This is an example of a dependency graph for production $A \rightarrow A A$
}


\begin{frame}{Visualization Tools}{Augmented dependency graph}

\begin{figure}[htbp]
    \centering

    \resizebox{.8\textwidth}{!}{
    \begin{tikzpicture}[->,>=Stealth,auto,
        thick,main node/.style={draw, rectangle, align=center, text width=1cm}]

\node[main node, ] (1) at (-2,4)   {$A_0.i_1$};
\node[main node, anchor=north west] (2) at(1.north east) {$A_0.i_2$};
\node[main node, anchor=south west] (3) at(2.north east) {$A_0.s_1$};
\node[main node, anchor=north west] (4) at(3.north east) {$A_0.s_2$};


\node[main node, ] (5) at (-6,0)   {$A_1.i_1$};
\node[main node, anchor=north west] (6) at(5.north east) {$A_1.i_2$};
\node[main node, anchor=south west] (7) at(6.north east) {$A_1.s_1$};
\node[main node, anchor=north west] (8) at(7.north east) {$A_1.s_2$};

\node[main node, ] (9) at (2,0)   {$A_2.i_1$};
\node[main node, anchor=north west] (10) at(9.north east) {$A_2.i_2$};
\node[main node, anchor=south west] (11) at(10.north east) {$A_2.s_1$};
\node[main node, anchor=north west] (12) at(11.north east) {$A_2.s_2$};

\draw (12.north) to[out=90, in=-90, looseness=1] (4.south);
\draw (2.south) to[out=-90, in=90, looseness=1] (9.north);
\draw (8.north) to[out=90, in=-90, looseness=1] (3.south);
\draw (1.south) to[out=-90, in=90, looseness=1] (5.north);

\draw (11.north) to[out=90, in=90, looseness=1.5] (10.north);
\draw (7.north) to[out=90, in=90, looseness=1.5] (6.north);

\draw[red] (5.south) to[out=-90, in=-90, looseness=1] (7.south);
\draw[red] (6.south) to[out=-90, in=-90, looseness=1] (8.south);
\draw[red] (9.south) to[out=-90, in=-90, looseness=1] (11.south);
\draw[red] (10.south) to[out=-90, in=-90, looseness=1] (12.south);

\end{tikzpicture} }

    \caption{\small Dependency graph $\mathit{DG}_{p: A \rightarrow A A}$ with SNC summary edges}
\end{figure}

\end{frame}

\note[itemize]{
\item This is an example of an augmented summary graph for the same production with SNC summary edges. Notice the red edges at the bottom.
}



\begin{frame}{Ordered AG Test}{Test if visit sequence evaluator exists (efficiently)}
By definition, there exists a visit sequence for \alert{$l$-ordered} attribute grammars but the membership test is \alert{NP-complete} \cite{ENGELFRIET1982283} so it's common/practical to use an OAG test which is a greedy algorithm that runs in \alert{polynomial time}.

\[ \mathit{OAG} \subseteq \mathit{l\text{-ordered}} \]

\end{frame}


\note[itemize]{
\item Testing for $l$-ordered is NP-complete and not practical at all
\item OAG is a subset of $l$-ordered and its membership test runs in a polynomial time
}


\begin{frame}{Ordered Attribute Grammar (OAG)}{Definition}

\begin{definition}
An attribute grammar is an Ordered Attribute Grammar (OAG) if for every production $p \in P$, the graph $\mathit{DG}_p^*$ is \alert{cycle free}.
\end{definition}

\begin{block}{Remark}
OAG test runs in polynomial time or $\mathcal{O}(|R|)$
\end{block}

\end{frame}

\note[itemize]{
\item It turns out the augmented dependency graphs can be helpful not just for visualization purposes
\item OAG membership test checks whether the augmented dependency graph with OAG summary edges is circular or not. If there is any circular dependency then it's not OAG.
\item This membership test is very straightforward to implement.
}



\subsection*{Extensions}

\begin{frame}{Circular Attribute Grammar}{Classical AG + allowing circularity}
\begin{definition}
An attribute grammar is \alert{circular} iff there exists a derivation tree of the context-free grammar whose \alert{attribute dependency has a cycle}. Conversely, an attribute grammar is non-circular if there is a valid schedule for every possible derivation tree.
\end{definition}
\end{frame}

\note[itemize]{
\item Let's talk about extensions to the classical attribute grammar
\item The first extension was allowing circular dependency by Farrow
\item Traditionally, even in the Knuth paper circularities have been treated as an error and have been avoided
\item But in mathematics or even programming its natural to define things circularly or recursively 
\item Detecting if attribute grammar is circular is not straightforward. It's actually NP-Complete.
\item Basically we need to test if there exists a schedule for every possible derivation of it and a context-free grammar may have an infinite number of derivations
}


\begin{frame}{Circular AG Evaluation}{Ascending chain condition}

Is it possible to evaluate circular attribute grammar? what if \alert{evaluation never terminates}?

\newlinevspace

$\Rightarrow$ Require that the domain of all attributes involved in cyclic chains can be arranged in a \alert{lattice of finite height} and that all semantic functions for these attributes are \alert{monotonic}

\[ x_{i+1} = f(x_i) \text{ where } x_0 = \bot \]

\end{frame}

\note[itemize]{
\item How to ensure that evaluation of circular attribute grammar terminates?
\item The answer is monotone functions
\item $x_0$ is a bottom value of the lattice and the height of the lattice is finite so if we run the cycle over and over again, we will eventually get a fixed-point value
}


\begin{frame}{Notation}{Monotone definition}

\begin{definition}
If $f:X \rightarrow Y$ is a \alert{set function} from a collection of sets $X$ to an ordered set $Y$, then $f$ is said to be monotone if whenever \alert{$A \subseteq B$} as elements of $X$, \alert{$f(A) \leq f(B)$}
\end{definition}

\end{frame}
\note[itemize]{
\item What is a monotone set function?
}



\begin{frame}{Example}{Synth function to calculate $s_1$, $s_2$ and $r$ synthesized attributes}

\scalebox{0.85}{
\begin{minipage}{0.7\linewidth}
\scriptsize
\begin{algorithmic}
        \Function{$\texttt{EVAL\_A\_s1}$}{$i_1$}
            \If{$\texttt{PRODUCTION} = A \rightarrow \epsilon$}
                \State \Return{$i_1 + 1$}
            \ElsIf{$\texttt{PRODUCTION} = A \rightarrow A A$}
                \State \Return{$ \texttt{EVAL\_A\_s2}( \texttt{EVAL\_A\_s1}(i_1)  ) $}
            \EndIf
        \EndFunction
        \State
        \Function{$\texttt{EVAL\_A\_s2}$}{$i_2$}
            \If{$\texttt{PRODUCTION} = A \rightarrow \epsilon$}
                \State \Return{$i_2 + 2$}
            \ElsIf{$\texttt{PRODUCTION} = A \rightarrow A A$}
                \State \Return{$ \texttt{EVAL\_A\_s2}( \texttt{EVAL\_A\_s1}(i_2)  ) $}
            \EndIf
        \EndFunction
        \State
        \Function{$\texttt{EVAL\_S\_r}$}{$\mathit{in}$}
            \State{\Return{$\texttt{EVAL\_A\_s2}(\texttt{EVAL\_A\_s1}(\mathit{in})) $}}
        \EndFunction
\end{algorithmic}
\end{minipage}}

\end{frame}

\note[itemize]{
\item This is an example of the synth function introduced by Farrow for the classical attribute grammar we saw previously
\item Notice how each function takes inherited attributes and uses them to calculate a single synthesized attribute
\item To support circular attributes Farrow added fixed-point loops inside of the function
}





\begin{frame}{Circular AG Evaluation}{Synth functions}
\alert{Synth function evaluators} for circular AG was introduced by Farrow in \cite{10.1145/13310.13320}

\newlinevspace

{ \footnotesize 

Pros:
\begin{itemize}
    \item Type of \alert{partially dynamic evaluation}
    \item Easy to implement
    \item Uses \alert{fixed-point loop} to ensure fixed-point in attribute values
\end{itemize}

Cons:
\begin{itemize}
    \item Allows \alert{nested loops}, that is if there is another cycle during the iterated evaluation of circularly defined attribute values. The number of iterations of the innermost loop becomes an \alert{exponential factor} of the nested level of the loop in the worst case.
\end{itemize} }

\end{frame}

\note[itemize]{
\item Synth functions are examples of partially dynamic evaluation
\item They are easy to implement
\item But they allow nested loops, that is if there is another cycle during the fixed-point evaluation of circularly defined attribute values
\item This means that number of iterations of the innermost loop becomes an exponential factor of the nested level loop in the worst case. This is not ideal.
}




\begin{frame}{Remote Attribute Grammar}{Classical AG + allowing references}
\begin{definition}
A remote attribute grammar is a tuple $(G,S,I,L,R,\alert{B},\alert{F})$ where \alert{$B$ is a set of objects} declared at each production and \alert{$F$ is a set of fields} that each object has.
\end{definition}

\newlinevspace

In RAG, we can access attribute values that are defined \alert{non-locally} whereas in classical all attributes are defined \alert{locally}.

\end{frame}

\note[itemize]{
\item This is a definition of remote attribute grammar or RAG. Basically, it extends classical attribute grammar and introduces a set of objects and a set of fields
}






\begin{frame}{Observation}{Partial field write}

It is valid to have \alert{multiple partial field write} for the same field of an object. This is \alert{unlike classical rule} where we can define an attribute instance \alert{once}.

\newlinevspace

This makes it challenging as the schedule for RAG should order instantiated rules such that \alert{read of the object's field} should be done when its value is \alert{final}. 

\end{frame}

\note[itemize]{
\item Remote attribute grammar extension introduces two new forms of semantic rule in addition to the classical form
\item Partial write of object field and Read of the object field
\item Note that attribute instance has to be defined once in a classical form and then we can read it
\item But the object field may be written to multiple times so we need to make sure we arrange the rules in the schedule in such a way that the reading of the object's field happens when the value is final
\item Objects are assumed instantiated before the evaluation begins
}





\begin{frame}[fragile=singleslide]{Example}{Remote attribute grammar to find semantic errors in a program}

\begin{centering}
\begin{multicols}{2}
\begin{Verbatim}[fontsize=\fontsize{5.5}{6}\selectfont]
program -> block
  block.scope = ROOT_SCOPE

block -> "begin" decls stmts "end"
  local scope = { decls: { }, enclosing: block.scope }
  decls.scope = scope
  stmts.scope = scope

decls ->

decls -> decls decl
  decls1.scope = decls0.scope
  decl.scope = decls0.scope

decl -> id ":" type ";"
  local d = { shape: type.shape, col: false } 
  decl.scope.decls <- { <id, d> }
  if not d.used then
    msgs <- { id + " not used" }

type -> "Integer"
  type.shape = INT_SHAPE

type -> "String"
  type.shape = STR_SHAPE

stmts -> 

stmts -> stmts stmt
  stmts1.scope = stmts0.scope
  stmt.scope = stmts0.scope

stmt -> block ";"
  block.scope = stmt.scope

stmt -> expr := expr
  expr1.scope = stmt.scope
  expr2.scope = stmt.scope
  if expr1.shape != expr2.shape then
    msgs <- { "type mismatch" }

expr -> INT_CONSTANT
  expr.shape = INT_SHAPE

expr -> STRING_CONSTANT
  expr.shape = STR_SHAPE

expr -> id
  local decl = lookup(id, expr.scope)
  expr.shape = decl.shape
  if decl == NOT_FOUND then
    msgs <- { id + " not declared" }
  else
    decl.used <- true
\end{Verbatim}
\end{multicols}
\end{centering}

\end{frame}

\note[itemize]{
\item This is the program analysis example using remote attribute grammar
\item Notice how much smaller it is now thanks to remote access and eliminating the need to pass attributes up and then down
}







\begin{frame}{Circular Remote Attribute Grammar}{Definition: Circular + Remote AG}

\begin{definition}
A circular remote attribute grammar is an \alert{extension of remote attribute grammars} and has the same form as remote attribute grammars, except \alert{certain attributes are circular} and \alert{uses of attribute occurrences in functions are declared monotone in some arguments}.
\end{definition}
\end{frame}

\note[itemize]{
\item This is the informal definition of circular remote attribute grammar or CRAG
\item It is a merge of two previous two extensions into one
}


\begin{frame}{Circular Remote Attribute Grammar}{Applications}
Obvious Applications for CRAG:

\begin{itemize}
    \item Unification (in type inference)
	\item Sub-typing with circular types (a class extending its own generic parameter)
	\item Detecting circular class extension in Cool semantic analyzer (e.g. A extends B, B extends C, C extends A)
\end{itemize}
\end{frame}

\note[itemize]{
\item There are many applications for a circular remote attribute grammar including ...
\item Cool is a programming language (classroom object-oriented language)
}


\begin{frame}[fragile=singleslide]{Circular Remote Attribute Grammar}{Evaluation strategy}
Hedin in \cite{10.1016/j.scico.2005.06.005} used fixed-point loops with \alert{demand evaluation} to evaluate circular remote attribute grammar.

\begin{Verbatim}[fontsize=\small]
    do {
    
        // Evaluate rules (again?)
        
    } while (currentValue \supset prevValue)
\end{Verbatim}

\newlinevspace

But, what about \alert{schedule}? how to formalize the validity of the schedule for CRAG?
\end{frame}

\note[itemize]{
\item This is a basic setup of a fixed-point loop.
\item Basically, we hold on to the previous value and then run the evaluation and then check whether the new value is a superset, NOT superset-equal to the previous value. And if that is the case then we re-run the loop.
}



\begin{frame}{Circular Remote Attribute Grammar}{Evaluation Terminating? Monotonicity}
$\Rightarrow$ If we put instantiated rules in a fixed-point loop, How to \alert{ensure evaluation terminates}?

\newlinevspace

Solution: \alert{Monotonicity} of arguments in a classical rule

\newlinevspace

\begin{block}{Remark}
The partial field write rule as defined in the definition of remote attribute grammar is a \alert{monotone} use.
\end{block}
\end{frame}

\note[itemize]{
\item Adding a monotonicity constraint helps ensure that fixed-point evaluation terminates.
}



\begin{frame}{Notation}{\Customorder{}}

Formally, a \customorder{} relation ($\lesssim$) satisfies the following properties:

\begin{enumerate}
    \item For all $x,y$ and $z$, if $x\lesssim y$ and $y\lesssim z$ then $x\lesssim z$ (\alert{transitivity}).
    \item For all $x, y$, then $x\lesssim y$ or $y\lesssim x$ must be true (strong connectedness or \alert{total})
    \item Neither reflexive nor irreflexive
\end{enumerate}

\end{frame}

\note[itemize]{
\item For reviewing purposes, this is a definition of \customorder{}: its reflexive, transitive, and total
\item we use less than with a tilde for \customorder{}
}



\begin{frame}{Circular Remote Attribute Grammar}{Schedule Definition}
    
\begin{definition}
A schedule then for a circular remote attribute grammar is a \alert{\customorder{}} $\lesssim$ on the \alert{instantiated rules}.
\end{definition}

\begin{exampleblock}{Observation}
Any \customorder{} on the instantiated rules is isomorphic to a total order on a partition of instantiated rules.
\end{exampleblock}

\end{frame}

\note[itemize]{
\item Schedule for CRAG is a \customorder{} of instantiated rules.
\item Note that the \customorder{} on the instantiated rules is isomorphic to the total order on a partition of instantiated rules.
\item By partition, we mean an unordered set. So there is no order between instantiated rules that belong to the same inner set.
}



\begin{frame}[fragile=singleslide]{Example}{CRAG Example}

\begin{multicols}{3}
\begin{Verbatim}[fontsize=\small]
S -> A B
    local l
    l = A.r
    B.i = l
    A.i = B.s
    S.x = l.f
A -> a
    object o
    o.f <- A.i
    A.r = o


B -> b
    local l
    l = B.i
    B.s = l.f
\end{Verbatim}
\end{multicols}

\newlinevspace

$\Rightarrow$ Notice the \alert{cycle} involving reading and writing of the same object

\end{frame}

\note[itemize]{
\item This is an example of circular remote attribute grammar
\item Notice $o.f$ gets $A.i$ using partial write and $A.i$ itself gets $B.s$ using classical rule
\item Then $B.s$ gets $l.f$ where $l$ is a local attribute assigned
\item Basically, we write to $o.f$ using the value of $o.f$
}



\begin{frame}[fragile=singleslide]{Example}{Instantiated CRAG with trivial derivation}

\begin{multicols}{3}
\begin{Verbatim}[fontsize=\small]
n0: S -> A B
    local l0
    r0: l0 = n1.r
    r1: n2.i = l0
    r2: n1.i = n2.s
    r3: n0.x = l0.f
n1: A -> a
    object o0
    r4: o0.f <- n1.i
    r5: n1.r = o0


n2: B -> b
    local l1
    r6: l1 = n2.i
    r7: n2.s = l1.f
\end{Verbatim}
\end{multicols}

\[
     \Big \{ \{ \hat{r}_5 \} < \{ \hat{r}_0 \} < \{ \hat{r}_1 \} < \{ \hat{r}_6 \} < \{ \hat{r}_4 , \hat{r}_7, \hat{r}_2 \} < \{ \hat{r}_3 \}  \Big \}
\]

\end{frame}

\note[itemize]{
\item This is the instantiated form of the circular remote attribute grammar we introduced in the previous slide using trivial derivation
\item the corresponding schedule is at the bottom
}


\begin{frame}{Trivial Schedule}{Observation}

Only when \alert{all uses are monotone}. 

$$ \Big\{ \{ \hat{r_0}, \dots, \hat{r_7} \} \Big \}$$

This happens when for all $\hat{r_1}, \hat{r_2} \in \hat{R}$, $\hat{r_1} \lesssim \hat{r_2} \wedge \hat{r_2} \lesssim \hat{r_1}$.

\end{frame}

\note[itemize]{
\item Trivial schedule is when we have all monotone functions
\item Basically all instantiated rules belong to the same level
\item So we just evaluate all instantiated rules over and over again until a fixed point is reached
}



\begin{frame}[fragile=singleslide]{Example}{CRAG Example with non-monotone function $h$}

\begin{multicols}{3}
\begin{Verbatim}[fontsize=\small]
n0: S -> A B
    local l
    r0: l = h(n1.r)
    r1: n2.i = h(l)
    r2: n1.i = n2.s
    r3: n0.x = h(l.f)
n1: A -> a
    object o
    r4: o.f <- n1.i
    r5: n1.r = h(o0)


n2: B -> b
    local l
    r6: l = h(n2.i)
    r7: n2.s = l.f
\end{Verbatim}
\end{multicols}

\newlinevspace

The trivial schedule \alert{does not work} for this example.

\end{frame}

\note[itemize]{
\item If we introduce non-monotone function $h$ in a cycle
\item Then this means that trivial schedule is not valid anymore
}


\begin{frame}{Example}{Circular visit}

% \begin{equation}
% \small
% \begin{gathered}
% \end{gathered}
% \end{equation}

\end{frame}

\note[itemize]{
\item These parts are not fully figured out yet
}


\begin{frame}{Fixed-Point Loops}{Case-by-case analysis of when the fixed-point loop is needed to avoid nesting fixed-point loops}

{ \small
\begin{tabular}{|p{0.4\linewidth} | p{0.5\linewidth}|}
\hline
% https://tex.stackexchange.com/questions/33486
\multicolumn{1}{|c|}{Visit Type} & \multicolumn{1}{c|}{Fixed-Point Loop?}   \\ 
\hline\hline
Circular visit inside of circular visit & No fixed-point loop. Since the parent visit repeats the evaluation, its loop includes the child visit as well.\\ \hline
Non-circular visit in a circular visit & No fixed-point loop. The visit has to evaluate only once. \\ \hline
Non-circular visit in a non-circular visit & No fixed-point loop. The visit has to evaluate only once. \\ \hline
A circular visit in a non-circular visit & Needs a fixed-point loop. \\ \hline
\end{tabular} }

\end{frame}

\note[itemize]{
\item This table describes the case-by-case analysis of when the fixed-point loop is needed
\item Notice that if a visit is circular and it is called from another circular visit then the fixed-point loop in the outer visit includes the child visit as well. And therefore no additional fixed-point loop in the child visit is required.
}