
\section{Definitions}

\subsection*{Preliminaries}

\begin{frame}{Context-Free Grammar (CFG)}{Foundation that attribute grammars built upon}

A grammar consists of:
\begin{itemize}
    \item a set of non-terminals, one of which is designated as the start variable
    \item a set of terminals
    \item a set of productions
\end{itemize}
\end{frame}

\note[itemize]{
\item What is a grammar or more specifically a context-free grammar?
\item Grammar is a tuple of ...
}

\begin{frame}[fragile=singleslide]{Example}{Grammar for a simple language}

\begin{multicols}{2}
\begin{Verbatim}[fontsize=\scriptsize]
program -> block

block -> "begin" decls stmts "end"

decls ->

decls -> decls decl

decl -> id ":" type ";"

type -> "Integer"

type -> "String"

stmts -> 

stmts -> stmts stmt

stmt -> block ";"

stmt -> expr := expr

expr -> INT_CONSTANT

expr -> STRING_CONSTANT

expr -> id
\end{Verbatim}
\end{multicols}


Source: \cite{Boyland1998AnalyzingDN}

\end{frame}

\note[itemize]{
\item This is an example of grammar that defines a simple program which declares some variables and assigns them to an expression
\item Notice that it starts from a program and goes to a block
\item Block consists of declarations and assignments
}


\begin{frame}[fragile=singleslide]{Example}{Derivation of this simple language}

\begin{Verbatim}[fontsize=\scriptsize,numbers=left,xleftmargin=5mm]
begin
   x : String;
   y : Integer;
	
   x := z;
   y := "hello world!";
end
\end{Verbatim}

Errors:
\begin{itemize}
    \item Use of undeclared variable?
    \item Type mismatch?
    \item Unused variable?
\end{itemize}

\newlinevspace

$\to$ How to detect these issues using attribute grammars?
\end{frame}

\note[itemize]{
\item This is a program or a derivation of context-free grammar that we saw in the previous slide
\item Notice there are multiple semantic errors in this program
}



\begin{frame}{Classical Attribute Grammar}{CFG + Rules}


A classical attribute grammar is a \alert{grammar} with the following added features:

\begin{itemize}
    \item Each non-terminal $X$ has a set of attributes $A(X)$
    \item $A(X)$ has two disjoint subsets
    \begin{itemize}
        \item $S(X)$, synthesized attributes, which are passed up the tree
        \item $I(X)$, inherited attributes which are passed down the tree
    \end{itemize}
    \item Set of local attributes associated with each production
    \item Each production of the grammar has a set of semantic rules
\end{itemize}

\end{frame}

\note[itemize]{
\item What is a classical attribute grammar?
\item It is a tuple of context-free grammar, set of attributes ...
}

\begin{frame}[fragile=singleslide]{Example}{Classical attribute grammar to find semantic errors in a program}


\begin{multicols}{2}
\begin{Verbatim}[fontsize=\fontsize{1}{1}\selectfont]
program -> block
	block.env = empty_env()
	program.msgs = block.msgs
	
block -> "begin" decls stmts "end"
	decls.envin = block.env
	stmts.env = decls.envout
	decls.uin = stmts.used
	block.used = decls.uout
	block.msgs = decls.msgs ++ stmts.msgs
	
decls ->
	decls.envout = decls.envin
	decls.uout = decls.uin
	decls.msgs = { }

decls -> decls decl
  decls1.envin = decls0.envin
  decl.envin = decls1.envout
  decls0.envout = decl.envout
  decl.uin = decls0.uin
  decls1.uin = decl.uout
  decls0.uout = decls1.uout
  decls0.msgs = decls1.msgs ++ decl.msgs

decl -> id ":" type ";"
  decl.envout = add_env(<id, type.shape>, decl.envin)
  decl.uout = decl.uin - id
  decl.msgs = if id in decl.uin then
                { }
              else
                { "unused: " + id }

type -> "Integer"
  type.shape = INT_SHAPE

type -> "String"
  type.shape = STR_SHAPE

stmt ->
  stmts.used = { }
  stmts.msgs = { }

stmts -> stmts stmt
  stmts1.env = stmts0.env
  stmt.env = stmts0.env
  stmts0.used = stmts1.used ++ stmt.used
  stmts0.msgs = stmts1.msgs ++ stmt.msgs

stmt -> block ";"
  block.env = stmt.env
  stmt.used = block.used
  stmt.msgs = block.msgs

stmts -> expr ":=" expr ";"
  expr1.env = stmt.env
  expr2.env = stmt.env
  stmt.used = expr1.used ++ expr2.used
  stmt.msgs = (if expr1.shape != expr2.shape then
                { "type mismatch" }
              else
                { }) ++ expr.msgs

expr -> INT_CONSTANT
  expr.shape = INT_SHAPE
  expr.used = { }
  expr.msgs = { }

expr -> STR_CONSTANT
  expr.shape = STR_SHAPE
  expr.used = { }
  expr.msgs = { }

expr -> id
  local shape = lookup(id, expr.env)
  expr.shape = shape
  expr.used = { id }
  expr.msgs = if shape == NOT_FOUND then
                { id + " not declared" }
              else
                { }
\end{Verbatim}
\end{multicols}

\end{frame}

\note[itemize]{
\item This is a classical attribute grammar the detects: type mismatch, unused variable and use of undeclared variable 
}


\begin{frame}{Instantiated Attribute Grammar}{Attribute Grammar + Derivation}
Given a \alert{derivation} of grammar, an attribute grammar becomes \alert{instantiated}:
\begin{itemize}
    \item Set of instantiated semantic rules where each attribute \alert{occurrence} is replaced with attribute \alert{instance}
\end{itemize}

\end{frame}

\note[itemize]{
\item Combining an attribute grammar and a derivation results in an instantiated attribute grammar where instead of attribute occurrences we have attribute instances.
}

\subsection*{Evaluations}

\begin{frame}{Evaluation}{Core concept}

Evaluation is a process of finding the \alert{values} of \alert{attribute instances}.

\end{frame}

\note[itemize]{
\item We observed that semantic information are stored in attributes
\item The values of attributes are result of attribute evaluation rules associated with productions of the grammar
\item and the evaluation is a process of finding the values of attribute instances
\item There are two types of evaluations: static and dynamic
\item Dynamic is a kind of evaluation where generated evaluator is tightly coupled with a particular derivation and it does not work given another derivation of the grammar.
\item Static evaluation is the opposite.
}


\begin{frame}{Demand Evaluation}{Straightforward evaluation method}
\begin{definition}
Demand evaluation is a kind of evaluation where each attribute instance access requires a call to evaluate the corresponding instantiated semantic rule that defines it.
\end{definition}

\end{frame}

\note[itemize]{
\item Demand evaluation is a type of dynamic evaluation where we replace access to the value of an attribute instance with a function call that defines the attribute in the first place
\item Basically, during the evaluation runtime, the evaluator tries to figure out which rule it should evaluate next
\item this form of evaluation is simple but it has some down sides
}

\begin{frame}[fragile=singleslide]{Example}{Simple yet abstract example of classical attribute grammar}
    
\begin{multicols}{3}
\begin{verbatim}
S -> A
  A.i1  = S.in
  A.i2  = A.s1
  S.out = A.s2




A -> A A
  A1.i1 = A0.i1
  A1.i2 = A1.s1
  A0.s1 = A1.s2
  A2.i1 = A0.i2
  A2.i2 = A2.s1
  A0.s2 = A2.s2

A -> epsilon
  A.s1 = A.i1 + 1
  A.s2 = A.i2 + 2
    
    
    
    
\end{verbatim}
\end{multicols}

Source: \cite{10.1145/225540.225544}
    
\end{frame}

\note[itemize]{
\item This is an example of classical attribute grammar
\item Notice root non-terminal $S$ has two attributes, one inherited and one synthesized
\item Similarly, non-terminal $A$ has two inherited and two synthesized attributes
\item This example is kind of abstract but its interesting
}


\begin{frame}[fragile=singleslide]{Derivation}{4 nodes in the tree}

\[
\lefteqn{\underbrace{\phantom{S \rightarrow A}}_{n_0}} S \rightarrow
\lefteqn{\overbrace{\phantom{A \rightarrow A A}}^{n_1}} A \rightarrow 
\lefteqn{\underbrace{\phantom{A A \rightarrow \epsilon}}_{n_2}} A A \rightarrow \epsilon
\lefteqn{\overbrace{A \rightarrow \epsilon}^{n_3}}
\]

\begin{center}
\scalebox{0.75}{\begin{forest}
  [
    $n_0$, name=n0
    [ $n_1$
        [$n_2$ [$\epsilon$]]
        [$n_3$ [$\epsilon$]]
    ]
  ]
\end{forest}}
\end{center}

\end{frame}

\note[itemize]{
\item This derivation results in 4 nodes in the syntax tree
}

\begin{frame}[fragile=singleslide]{Example}{Instantiated attribute grammar}


\begin{multicols}{3}
\begin{Verbatim}[fontsize=\scriptsize]
n0: S -> A
  r0 : n1.i1  = n0.in
  r1 : n1.i2  = n1.s1
  r2 : n0.out = n1.s2




n1: A -> A A
  r3 : n2.i1 = n1.i1
  r4 : n2.i2 = n2.s1
  r5 : n1.s1 = n2.s2
  r6 : n3.i1 = n1.i2
  r7 : n3.i2 = n3.s1
  r8 : n1.s2 = n3.s2

n2: A -> epsilon
  r9 : n2.s1 = n2.i1 + 1
  r10: n2.s2 = n2.i2 + 2
    
n3: A -> epsilon
  r11: n3.s1 = n3.i1 + 1
  r12: n3.s2 = n3.i2 + 2
\end{Verbatim}
\end{multicols}

The sequence of steps needed to evaluate $\alert{n_0.\mathit{out}}$:
$\alert{n_0.\mathit{out}} \to \alert{r_2}{:} n_o.\mathit{out} = n_1.s_2 \to \alert{r_8}{:} n_1.s_2 = n_3.s_2 \to \alert{r_{12}}{:}n_3.s_2 = \dots$

\end{frame}

\note[itemize]{
\item This is the instantiated form of an attribute grammar we saw in the previous slide
\item $n_0$ to $n_3$ are tree nodes
\item $n$ followed by dot followed by attribute name is called an attribute instance
\item Also, notice the sequence of steps a demand evaluator needs to take during the evaluation runtime to evaluate root node's synthesized attribute $n_0.\mathit{out}$
\item This sequence of instantiated rules used to evaluate all attributes is called a schedule
\item We have to use a topological sort to find the schedule
}

\begin{frame}{Schedule}{Total order of instantiated rules}
What makes a schedule (total order on instantiated rules) valid?

\newlinevspace

$\to$ \alert{No use of attribute instance before it is defined first}

\end{frame}

\note[itemize]{
\item In a valid schedule, we have to arrange the instantiated rules such that no attribute instance is used before it is defined first.
\item So definition of an attribute instance has to precede the use.
}

\begin{frame}{Demand Evaluation}{Pros and cons}
Pros:
\begin{itemize}
    \item Can benefit form \alert{caching to prevent re-evaluation}
    \item Easy to implement
\end{itemize}

Cons:
\begin{itemize}
    \item Does not detect cycles before evaluation begins or \alert{may not terminate}
    \item Space complexity if \alert{caching} is used: $\mathcal{O}(|\hat{V}|)$
    \item Time complexity of: $\mathcal{O}(| \hat{V} | \times | \hat{R} |)$ (for classical AG)
\end{itemize}
\end{frame}

\note[itemize]{
\item Demand evaluation has some down sides
\item We have to use a cache to avoid exponential time complexity because everything will get evaluated over and over again and doing so will impact the space complexity
\item Also, it does not detect cycles before evaluation begins and we do not know if evaluation is going to terminate or not. So this is not ideal.
}


\begin{frame}{Schedule Evaluation}{Finding the order of evaluation of instantiated rules before evaluation runtime}

Given this \emph{schedule}, evaluate the AG:

\begin{equation}
\begin{split}
\mathit{schedule} = \Big \{\hat{r}_0 < \hat{r}_3 < \hat{r}_9 < \hat{r}_4 < \hat{r}_{10} < \hat{r}_5 < \hat{r}_1 < \hat{r}_6 \\
< \hat{r}_{11} < \hat{r}_7 < \hat{r}_{12} < \hat{r}_8 < \hat{r}_2 \Big \}    
\end{split}
\end{equation}

\begin{alertblock}{Observation}
Finding the schedule requires topological sort of attribute instances: $\mathcal{O}(| V +  E|)$ where $V = \hat{V}$ and $E = |\hat{V}  \times  \hat{R}|$
\end{alertblock}
\end{frame}

\note[itemize]{
\item Schedule evaluation is a type of dynamic evaluation where we find the schedule beforehand and then during the evaluation runtime we evaluate the instantiated rules according to the schedule.
\item This is the schedule for the instantiated attribute grammar we saw in the previous slide
\item We use $r$ hat to denote for instantiated rules
}




\begin{frame}{Schedule Evaluation}{Pros and cons}
Pros:
\begin{itemize}
    \item If scheduler finds a schedule, then evaluation \alert{will terminate}
    \item Easy to implement
    \item \alert{No re-evaluation}
    \item Better space complexity as caching is not used
    \item Time complexity of: $\mathcal{O}(| \hat{R} |)$ (for classical AG)
\end{itemize}

Cons:
\begin{itemize}
    \item Schedule \alert{works only for one derivation} of attribute grammar
\end{itemize}
\end{frame}

\note[itemize]{
\item Schedule evaluator runs in a linear time for classical attribute grammar
\item Doesn't require a cache
\item But it only works for one derivation, and if we are given a different derivation then we need to find a different schedule. So this is not ideal.
}






\begin{frame}{Static Evaluation}{Alternative evaluation method: Constructed independent of a derivation}

\begin{itemize}
    \item What if there was a way to \alert{statically} evaluate attribute grammars?
    \begin{itemize}
        \item Generate evaluator \alert{once} and would \alert{work for all possible derivations} of an attribute grammar.
    \end{itemize}
    \item What \alert{constraints} need to be true for such an attribute grammar to have a static evaluator?
    \item Does evaluation \alert{terminate}?
    \item How to verify if static evaluation is \alert{valid}?
\end{itemize}
\end{frame}

\note[itemize]{
\item What if there was a better way to evaluate attributes? some kind of static evaluator where it would create the schedule in the runtime and evaluate a classical attribute grammar in a linear time? this would be very ideal.
}


\begin{frame}{Visit Sequence Evaluation}{Static evaluator}

$\to$ \alert{Visit sequence evaluation} is a \alert{type of static evaluation}.

\newlinevspace

Pros:
\begin{itemize}
    \item Evaluation \alert{will terminate}
    \item Easy to implement
    \item \alert{No re-evaluation}
    \item Better space complexity as caching is not used
    \item Time complexity of: $\mathcal{O}(| \hat{R} |)$ (for classical AG)
    \item \alert{Practical}: can be generated independent of derivation
\end{itemize}

Cons:
\begin{itemize}
    \item Only works on \alert{$l$-ordered} class of attribute grammars
\end{itemize}
\end{frame}

\note[itemize]{
\item Kastens introduced $l$-ordered class of attribute grammars and introduced a type of static evaluator called a visit sequence evaluator. 
\item Visit sequence evaluator does not require caching
\item and runs in linear time for a classical attribute grammar
\item and can be generated once and works for all derivations of a grammar
\item but only works for $l$-ordered class of attribute grammars
}



\begin{frame}[fragile=singleslide]{Example}{Visit sequence evaluator}

$\to$ Set of \alert{recursive functions} where each function takes an \alert{instance of non-terminal} (derivation tree node)

\begin{multicols}{2}
\begin{Verbatim}[fontsize=\scriptsize]
visit_S(n: S -> A)
    A.i1 = S.in
    - visit_A_part1(A)
    A.i2 = A.s1
    - visit_A_part2(A)
    S.out = A.s2

visit_A_part1(n: A -> A A)
    A1.i1 = A0.i1
    - visit_A_part1(A1)
    A1.i2 = A1.s1
    - visit_A_part2(A1)
    A0.s1 = A1.s2
visit_A_part2(n: A -> A A)
    A2.i1 = A0.i2
    - visit_A_part1(A2)
    A2.i2 = A2.s1
    - visit_A_part2(A2)
    A0.s2 = A2.s2

visit_A_part1(n: A -> epsilon)
    A.s1 = A.i1 + 1

visit_A_part2(n: A -> epsilon)
    A.s2 = A.i2 + 1
    
\end{Verbatim}
\end{multicols}
\end{frame}

\note[itemize]{
\item This is a visit sequence evaluator for the classical attribute grammar we described previously
}


\begin{frame}{$l$-ORD}{$T(X)$: Total order of attributes for non-terminal $X$ }

\[  T(S) = \{ S.\mathit{in} < S.\mathit{out}  \}  \]

\[  T(A) = \{ A.i_1 < A.i_2 < A.s_1 < A.s_2 \}  \]

\newlinevspace

$\to$ AG is $l$-ordered if exists a $T(X)$  for all non-terminal $X \in N$ such that its \alert{compatible} with $\mathit{Ord}(\mathit{AO}(p))$ and $\mathit{Ord}(R(p))$ where $p: X \rightarrow \alpha$. 

\end{frame}

\note[itemize]{
\item What is an $l$-ordered class of attribute grammars?
\item We say that AG is $l$-ordered if there is a total order of attribute occurrences for a non-terminal such that its compatible with the ordered set of all attribute occurrences for a production $\mathit{AO}(p)$ and ordered set of all rules associated with a production $R(p)$. 
}



\begin{frame}{Visit Sequence}{Protocol}

\begin{definition}
A \emph{Protocol} $\Pi(X)$ is an \alert{ordered partition of attributes} for each non-terminal $X \in N$, where it can include an empty set or multiple synthesized or inherited attributes.
\end{definition}

\newlinevspace

\begin{examples}
For example, $\Pi(A)$ is the following:
\[ \Pi(A) = \Big\{ \{ A.i_1, A.s_1 \} < \{ A.i_2, A.s_2 \} \Big\} \]
\end{examples}

Visit Sequence has to be compatible with $\mathit{Ord}(R(p))$ and $\Pi(X_i)$

\end{frame}

\note[itemize]{
\item To understand a visit sequence we first need to understand a protocol which is like an interface in a programming language
\item A protocol for a non-terminal is an ordered partition of attributes. This may include an empty set or multiple synthesized or inherited attributes.
\item A visit sequence for a production has to be compatible with an ordered set of all rules associated with a production $R(p)$ and protocol for all non-terminals involving in a production.
}



\begin{frame}{Visualization Tools}{Dependency graph}

\begin{figure}[htbp]
    \centering
    \resizebox{.8\textwidth}{!}{
    \begin{tikzpicture}[->,>=Stealth,auto,
        thick,main node/.style={draw, rectangle, align=center, text width=1cm}]

\node[main node, ] (1) at (-2,4)   {$A_0.i_1$};
\node[main node, anchor=north west] (2) at(1.north east) {$A_0.i_2$};
\node[main node, anchor=south west] (3) at(2.north east) {$A_0.s_1$};
\node[main node, anchor=north west] (4) at(3.north east) {$A_0.s_2$};


\node[main node, ] (5) at (-6,0)   {$A_1.i_1$};
\node[main node, anchor=north west] (6) at(5.north east) {$A_1.i_2$};
\node[main node, anchor=south west] (7) at(6.north east) {$A_1.s_1$};
\node[main node, anchor=north west] (8) at(7.north east) {$A_1.s_2$};

\node[main node, ] (9) at (2,0)   {$A_2.i_1$};
\node[main node, anchor=north west] (10) at(9.north east) {$A_2.i_2$};
\node[main node, anchor=south west] (11) at(10.north east) {$A_2.s_1$};
\node[main node, anchor=north west] (12) at(11.north east) {$A_2.s_2$};

\draw (12.north) to[out=90, in=-90, looseness=1] (4.south);
\draw (2.south) to[out=-90, in=90, looseness=1] (9.north);
\draw (8.north) to[out=90, in=-90, looseness=1] (3.south);
\draw (1.south) to[out=-90, in=90, looseness=1] (5.north);

\draw (11.north) to[out=90, in=90, looseness=1.5] (10.north);
\draw (7.north) to[out=90, in=90, looseness=1.5] (6.north);


\end{tikzpicture}}

    \caption{Dependency graph $\mathit{DG}_{p: A \rightarrow A A}$}
\end{figure}

\end{frame}

\note[itemize]{
\item We can draw a dependency graph to visualize dependencies between attribute occurrences in a production
\item This is an example of dependency graph for production $A \rightarrow A A$
}


\begin{frame}{Visualization Tools}{Augmented dependency graph}

\begin{figure}[htbp]
    \centering

    \resizebox{.8\textwidth}{!}{
    \begin{tikzpicture}[->,>=Stealth,auto,
        thick,main node/.style={draw, rectangle, align=center, text width=1cm}]

\node[main node, ] (1) at (-2,4)   {$A_0.i_1$};
\node[main node, anchor=north west] (2) at(1.north east) {$A_0.i_2$};
\node[main node, anchor=south west] (3) at(2.north east) {$A_0.s_1$};
\node[main node, anchor=north west] (4) at(3.north east) {$A_0.s_2$};


\node[main node, ] (5) at (-6,0)   {$A_1.i_1$};
\node[main node, anchor=north west] (6) at(5.north east) {$A_1.i_2$};
\node[main node, anchor=south west] (7) at(6.north east) {$A_1.s_1$};
\node[main node, anchor=north west] (8) at(7.north east) {$A_1.s_2$};

\node[main node, ] (9) at (2,0)   {$A_2.i_1$};
\node[main node, anchor=north west] (10) at(9.north east) {$A_2.i_2$};
\node[main node, anchor=south west] (11) at(10.north east) {$A_2.s_1$};
\node[main node, anchor=north west] (12) at(11.north east) {$A_2.s_2$};

\draw (12.north) to[out=90, in=-90, looseness=1] (4.south);
\draw (2.south) to[out=-90, in=90, looseness=1] (9.north);
\draw (8.north) to[out=90, in=-90, looseness=1] (3.south);
\draw (1.south) to[out=-90, in=90, looseness=1] (5.north);

\draw (11.north) to[out=90, in=90, looseness=1.5] (10.north);
\draw (7.north) to[out=90, in=90, looseness=1.5] (6.north);

\draw[red] (5.south) to[out=-90, in=-90, looseness=1] (7.south);
\draw[red] (6.south) to[out=-90, in=-90, looseness=1] (8.south);
\draw[red] (9.south) to[out=-90, in=-90, looseness=1] (11.south);
\draw[red] (10.south) to[out=-90, in=-90, looseness=1] (12.south);

\end{tikzpicture} }

    \caption{\small Augmented dependency graph $\mathit{DG}_{p: A \rightarrow A A}$ with SNC summary edges}
\end{figure}

\end{frame}

\note[itemize]{
\item This is an example of augmented summary graph for the same production with SNC summary edges. Notice the red edges at the bottom.
}



\begin{frame}{Ordered AG Test}{Test if visit sequence evaluator exists (efficiently)}
By definition, there exist a visit sequence for \alert{$l$-ordered} attribute grammars but membership test is \alert{NP-complete} \cite{ENGELFRIET1982283} so its common/practical to use an OAG test which is a greedy algorithm that runs in \alert{polynomial time}.

\[ \mathit{OAG} \subseteq \mathit{l\text{-ordered}} \]

\end{frame}


\note[itemize]{
\item Testing for $l$-ordered is NP-complete and not practical at all
\item OAG is a subset of $l$-ordered and its membership test is runs in a polynomial time
}


\begin{frame}{Ordered Attribute Grammar (OAG)}{Definition}

\begin{definition}
An attribute grammar is an Ordered Attribute Grammar (OAG) if for every production $p \in P$, the graph $\mathit{DG}_p^*$ is \alert{cycle free}.
\end{definition}

\begin{block}{Remark}
OAG test runs in polynomial time or $\mathcal{O}(|R|)$
\end{block}

\end{frame}

\note[itemize]{
\item It turns out the augmented dependency graphs can be helpful not just for visualization purposes
\item OAG membership test checks whether augmented dependency graph with OAG summary edges is circular or not. If there is any circular dependency then its not OAG.
\item This test is very straightforward.
}



\subsection*{Extensions}

\begin{frame}{Circular Attribute Grammar}{Classical AG + allowing circularity}
\begin{definition}
An attribute grammar is \alert{circular} iff there exists a derivation tree of the context-free grammar whose \alert{attribute dependency has a cycle}. Conversely, an attribute grammar is non-circular if there is a valid schedule for every possible derivation tree.
\end{definition}
\end{frame}

\note[itemize]{
\item Lets talk about extensions to the classical attribute grammar
\item The first extension was allowing circular dependency by Farrow
\item Traditionally even in the Knuth paper circularities have been treated as an error and have been avoided
\item But in mathematics or even programming its natural to define things circularly or recursively 
}


\begin{frame}{Circular AG Evaluation}{Ascending chain condition}

Is it possible to evaluate circular attribute grammars? what if \alert{evaluation never terminates}?

\newlinevspace

$\to$ Require that the domain of all attributes involved in cyclic chains can be arranged in a \alert{lattice of finite height} and that all semantic functions for these attributes are \alert{monotonic}

\[ x_{i+1} = f(x_i) \text{ where } x_0 = \bot \]

\end{frame}

\note[itemize]{
\item How to ensure that evaluation of circular attribute grammar terminates?
\item The answer is monotone functions
}




\begin{frame}{Example}{Synth function to calculate $s_1$, $s_2$ and $r$ synthesized attributes}

\scalebox{0.85}{
\begin{minipage}{0.7\linewidth}
\scriptsize
\begin{algorithmic}
        \Function{$\texttt{EVAL\_A\_s1}$}{$i_1$}
            \If{$\texttt{PRODUCTION} = A \rightarrow \epsilon$}
                \State \Return{$i_1 + 1$}
            \ElsIf{$\texttt{PRODUCTION} = A \rightarrow A A$}
                \State \Return{$ \texttt{EVAL\_A\_s2}( \texttt{EVAL\_A\_s1}(i_1)  ) $}
            \EndIf
        \EndFunction
        \State
        \Function{$\texttt{EVAL\_A\_s2}$}{$i_2$}
            \If{$\texttt{PRODUCTION} = A \rightarrow \epsilon$}
                \State \Return{$i_2 + 2$}
            \ElsIf{$\texttt{PRODUCTION} = A \rightarrow A A$}
                \State \Return{$ \texttt{EVAL\_A\_s2}( \texttt{EVAL\_A\_s1}(i_2)  ) $}
            \EndIf
        \EndFunction
        \State
        \Function{$\texttt{EVAL\_S\_r}$}{$\mathit{in}$}
            \State{\Return{$\texttt{EVAL\_A\_s2}(\texttt{EVAL\_A\_s1}(\mathit{in})) $}}
        \EndFunction
\end{algorithmic}
\end{minipage}}

\end{frame}

\note[itemize]{
\item This is an example of synth function introduced by Farrow for the classical attribute grammar we saw previously
\item Notice how each function takes inherited attributes and uses it to calculate a synthesized attribute
\item To support circular attributes Farrow added fixed-point loops inside of the function
}





\begin{frame}{Circular AG Evaluation}{Synth functions}
\alert{Synth function evaluators} for circular AG was introduced by Farrow in \cite{10.1145/13310.13320}

\newlinevspace

{ \footnotesize 

Pros:
\begin{itemize}
    \item Type of \alert{partially dynamic evaluation}
    \item Easy to implement
    \item Uses \alert{fixed-point loop} to ensure fixed-point in attribute values
\end{itemize}

Cons:
\begin{itemize}
    \item Allows \alert{nested loops}, that is if there is another cycle during the iterated evaluation of circularly defined attribute values. Number of iteration of the innermost loop becomes an \alert{exponential factor} of the nested level of the loop in the worst case.
\end{itemize} }

\end{frame}

\note[itemize]{
\item Synth functions are example of partially dynamic evaluation
\item They are easy to implement
\item But they allows nested loops, that is if there is another cycle during the fixed-point evaluation of circularly defined attribute values
\item This means that number of iterations of the innermost loop becomes an exponential factor of the nested level loop in the worst case. This is not ideal.
}




\begin{frame}{Remote Attribute Grammar}{Classical AG + allowing references}
\begin{definition}
A remote attribute grammar is a tuple $(G,S,I,L,R,\alert{B},\alert{F})$ where \alert{$B$ is a set of objects} declared at each production and \alert{$F$ is a set of fields} that each object has.
\end{definition}

\newlinevspace

In RAG, we can access attribute values that are defined \alert{non-locally} whereas in classical all attributes are defined \alert{locally}.

\end{frame}

\note[itemize]{
\item This is a definition of remote attribute grammar or RAG. Basically it extends classical attribute grammar and introduces set of objects and set of fields
}






\begin{frame}{Observation}{Partial field write}

It is valid to have \alert{multiple partial field write} for the same field of an object. This is \alert{unlike classical rule} where we can define an attribute instance \alert{once}.

\newlinevspace

This makes it challenging as schedule for RAG should order instantiated rules such that \alert{read of the object's field} should be done when its value is \alert{final}. 

\end{frame}

\note[itemize]{
\item Remote attribute grammar introduces two new form of semantic rule in addition to classical form
\item Partial write of object field and read of object field
\item Note that attribute instance has to be defined once in a classical form and then we can read it
\item But object field may be written to multiple times so we need to make sure we arrange the rules in the schedule in such a way that the reading of object's field happens when the value is final
}





\begin{frame}[fragile=singleslide]{Example}{Remote attribute grammar to find semantic errors in a program}

\begin{centering}
\begin{multicols}{2}
\begin{Verbatim}[fontsize=\fontsize{5.5}{6}\selectfont]
program -> block
  block.scope = ROOT_SCOPE

block -> "begin" decls stmts "end"
  local scope = { decls: { }, enclosing: block.scope }
  decls.scope = scope
  stmts.scope = scope

decls ->

decls -> decls decl
  decls1.scope = decls0.scope
  decl.scope = decls0.scope

decl -> id ":" type ";"
  local d = { shape: type.shape, col: false } 
  decl.scope.decls <- { <id, d> }
  if not d.used then
    msgs <- { id + " not used" }

type -> "Integer"
  type.shape = INT_SHAPE

type -> "String"
  type.shape = STR_SHAPE

stmts -> 

stmts -> stmts stmt
  stmts1.scope = stmts0.scope
  stmt.scope = stmts0.scope

stmt -> block ";"
  block.scope = stmt.scope

stmt -> expr := expr
  expr1.scope = stmt.scope
  expr2.scope = stmt.scope
  if expr1.shape != expr2.shape then
    msgs <- { "type mismatch" }

expr -> INT_CONSTANT
  expr.shape = INT_SHAPE

expr -> STRING_CONSTANT
  expr.shape = STR_SHAPE

expr -> id
  local decl = lookup(id, expr.scope)
  expr.shape = decl.shape
  if decl == NOT_FOUND then
    msgs <- { id + " not declared" }
  else
    decl.used <- true
\end{Verbatim}
\end{multicols}
\end{centering}

\end{frame}

\note[itemize]{
\item This is the program analysis example using remote attribute grammar
\item Notice that how much smaller it is now thanks to remote access and eliminating the need to passing attributes up and down
}




\begin{frame}{Notation}{Monotone definition}

\begin{definition}
If $f:X \rightarrow Y$ is a \alert{set function} from a collection of sets $X$ to an ordered set $Y$, then $f$ is said to be monotone if whenever \alert{$A \subseteq B$} as elements of $X$, \alert{$f(A) \leq f(B)$}
\end{definition}

\end{frame}
\note[itemize]{
\item What is a monotone function?
}


\begin{frame}{Circular Remote Attribute Grammar}{Definition: Circular + Remote AG}

\begin{definition}
Circular remote attribute grammar is an \alert{extension of remote attribute grammars} and has the same form as remote attribute grammars, except \alert{certain attributes are circular} and \alert{some functions are declared monotone in some arguments}.
\end{definition}
\end{frame}

\note[itemize]{
\item Definition of circular remote attribute grammar or CRAG
}


\begin{frame}{Circular Remote Attribute Grammar}{Applications}
Obvious Applications for CRAG:

\begin{itemize}
    \item Unification (in type inference)
	\item Sub-typing with circular types (class extending its own generic parameter)
	\item Detecting circular class extension in Cool semantic analyzer (e.g. A extends B, B extends C, C extends A)
\end{itemize}
\end{frame}

\note[itemize]{
\item There are many applications for a circular remote attribute grammar
\item Cool is a programming language (classroom object oriented language)
}


\begin{frame}[fragile=singleslide]{Circular Remote Attribute Grammar}{Evaluation strategy}
Hedin in \cite{10.1016/j.scico.2005.06.005} used fixed-point loops with \alert{demand evaluation} to evaluate circular remote attribute grammar.

\begin{Verbatim}[fontsize=\small]
    do {
    
        // Evaluate rules (again?)
        
    } while (currentValue \supset prevValue)
\end{Verbatim}

\newlinevspace

But, what about \alert{schedule}? how to formalize validity of schedule for CRAG?
\end{frame}

\note[itemize]{
\item This is a basic setup of a fixed-point loop.
\item Basically, we hold on to the previous value and then we run the evaluation and then check whether the new value is a superset and NOT superset-equal of the previous value. And if that is the case then we re-run the loop.
}



\begin{frame}{Circular Remote Attribute Grammar}{Evaluation Terminating? Monotonicity}
$\to$ If we put instantiated rules in a fixed-point loop, How to \alert{ensure evaluation terminates}?

\newlinevspace

Solution: \alert{Monotonicity} of arguments in a classical rule

\newlinevspace

\begin{block}{Remark}
Partial field write rule as defined in definition of remote attribute grammar \alert{is a monotone operation}.
\end{block}
\end{frame}

\note[itemize]{
\item Adding mononicity constraint helps ensure that fixed-point evaluation terminates.
}



\begin{frame}{Notation}{Total pre-order}

Formally, a total pre-order relation $\lesssim$ satisfies the following properties:

\begin{enumerate}
    \item For all $x,y$ and $z$, if $x\lesssim y$ and $y\lesssim z$ then $x\lesssim z$ (\alert{transitivity}).
    \item For all $x, y$, then $x\lesssim y$ or $y\lesssim x$ must be true (strong connectedness or \alert{total}). Hence, for all $x$, then $x\lesssim x$ must also be true (\alert{reflexivity}).
\end{enumerate}    

\end{frame}

\note[itemize]{
\item This is a definition of total pre-order: its reflexive, transitive and total
}



\begin{frame}{Circular Remote Attribute Grammar}{Schedule Definition}
    
\begin{definition}
A schedule then for a circular remote attribute grammar is a \alert{total pre-order} $\lesssim$ on the \alert{instantiated rules}.
\end{definition}

\begin{exampleblock}{Observation}
Any total pre-order on the instantiated rules is isomorphic to a total order on a partition of instantiated rules.
\end{exampleblock}

\end{frame}

\note[itemize]{
\item Schedule for CRAG is a total pre-order of instantiated rules.
\item Note that total pre-order on the instantiated rules is isomorphic to a total order on a partition of instantiated rules.
\item By partition, we mean an un-ordered set. So there is no order between instantiated rules that belong to the same inner set.
}



\begin{frame}[fragile=singleslide]{Example}{CRAG Example}

\begin{multicols}{3}
\begin{Verbatim}[fontsize=\small]
S -> A B
    local l
    l = A.r
    B.i = l
    A.i = B.s
    S.x = l.f
A -> a
    object o
    o.f <- A.i
    A.r = o


B -> b
    local l
    l = B.i
    B.s = l.f
\end{Verbatim}
\end{multicols}

\newlinevspace

$\to$ Notice the \alert{cycle} involving reading and writing of the same object

\end{frame}

\note[itemize]{
\item This is an example of circular remote attribute grammar}



\begin{frame}[fragile=singleslide]{Example}{Instantiated CRAG with trivial derivation}

\begin{multicols}{3}
\begin{Verbatim}[fontsize=\small]
n0: S -> A B
    local l0
    r0: l0 = n1.r
    r1: n2.i = l0
    r2: n1.i = n2.s
    r3: n0.x = l0.f
n1: A -> a
    object o0
    r4: o0.f <- n1.i
    r5: n1.r = o0


n2: B -> b
    local l1
    r6: l1 = n2.i
    r7: n2.s = l1.f
\end{Verbatim}
\end{multicols}

\[
     \Big \{ \{ \hat{r}_5 \} < \{ \hat{r}_0 \} < \{ \hat{r}_1 \} < \{ \hat{r}_6 \} < \{ \hat{r}_4 , \hat{r}_7, \hat{r}_2 \} < \{ \hat{r}_3 \}  \Big \}
\]

\end{frame}

\note[itemize]{
\item This is the instantiated form of the circular remote attribute grammar we introduced in the previous slide using trivial derivation and the corresponding schedule is at the bottom
}


\begin{frame}{Trivial Schedule}{Observation}

Only when \alert{all functions are monotone}. 

$$ \Big\{ \{ \hat{r_0}, \dots, \hat{r_7} \} \Big \}$$

This happens when for all $\hat{r_1}, \hat{r_2} \in \hat{R}$, $\hat{r_1} \lesssim \hat{r_2} \wedge \hat{r_2} \lesssim \hat{r_1}$.

\end{frame}

\note[itemize]{
\item Trivial schedule is when we have all monotone functions
\item Basically all instantiated rules belong to the same level
\item So we just evaluate all instantiated rules over and over again until fixed point is reached
}



\begin{frame}[fragile=singleslide]{Example}{CRAG Example with non-monotone function $h$}

\begin{multicols}{3}
\begin{Verbatim}[fontsize=\small]
n0: S -> A B
    local l
    r0: l = h(n1.r)
    r1: n2.i = h(l)
    r2: n1.i = n2.s
    r3: n0.x = h(l.f)
n1: A -> a
    object o
    r4: o.f <- n1.i
    r5: n1.r = h(o0)


n2: B -> b
    local l
    r6: l = h(n2.i)
    r7: n2.s = l.f
\end{Verbatim}
\end{multicols}

\newlinevspace

The trivial schedule \alert{does not work} for this example.

\end{frame}

\note[itemize]{
\item If we introduce non-monotone function $h$ in a cycle
\item Then this means that trivial schedule does not work anymore
}


\begin{frame}{Example}{Circular visit}

\begin{equation}
\small
\begin{gathered}
\Pi(S) =  \Big \{   \{ S.x \}      \Big \} \\
\Pi(A) =  \Big \{   \{  A.i, A.r \}^c      \Big \} \\
\Pi(B) =  \Big \{   \{  B.i, B.s \}^c      \Big \}
\end{gathered}
\end{equation}

\begin{equation}
\small
\begin{gathered}
\mathscr{V}(p: S \rightarrow A B) = \Big \{  \{  \mathit{visit}(A, 1) <  (l \texttt{=} A.r) < \mathit{visit}(B, 1)  \}    \Big \} \\
\mathscr{V}(p: A \rightarrow a) = \Big \{  \{  (o.f \sqsupseteq A.i)  < (A.r \texttt{=} o)  \}^c    \Big \} \\
\mathscr{V}(p: B \rightarrow b) = \Big \{  \{  (l \texttt{=} B.i) < (B.s \texttt{=} l.f)  \}^c    \Big \}
\end{gathered}
\end{equation}

\end{frame}

\note[itemize]{
\item These parts are not fully figured out yet
\item But we need mark some visits as circular and also some protocols as circular as well
}


\begin{frame}{Fixed-Point Loops}{Case-by-case analysis of when fixed-point loop is needed to avoid nesting fixed-point loops}

{ \small
\begin{tabular}{|p{0.4\linewidth} | p{0.5\linewidth}|}
\hline
% https://tex.stackexchange.com/questions/33486
\multicolumn{1}{|c|}{Visit Type} & \multicolumn{1}{c|}{Fixed-Point Loop?}   \\ 
\hline\hline
Circular visit inside of circular visit & No fixed-point loop. Since the parent visit repeats the evaluation, its loop includes the child visit as well.\\ \hline
Non-circular visit in circular visit & No fixed-point loop. Visit has to evaluate only once. \\ \hline
Non-circular visit in non-circular visit & No fixed-point loop. Visit has to evaluate only once. \\ \hline
Circular visit in non-circular visit & Needs fixed-point loop. \\ \hline
\end{tabular} }

\end{frame}

\note[itemize]{
\item This table describes the case-by-case analysis of when fixed-point loop is needed
\item Notice that if a visit is circular and it is called from another circular visit then the fixed-point loop in the outer visit includes the child visit as well. And therefore no additional fixed-point loop in the child visit is required.
}